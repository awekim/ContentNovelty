{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bc1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'D:/DataforPractice/ContentNovelty/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe480a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert .pasrquet to .csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(dir+'3_external_with_novelty.parquet')\n",
    "df.to_csv(dir+'3_external_with_novelty.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "df = pd.read_parquet(dir+'3_internal_with_novelty.parquet')\n",
    "df.to_csv(dir+'3_internal_with_novelty.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dba18b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pubid</th>\n",
       "      <th>EU_NUTS_ID</th>\n",
       "      <th>period</th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>ID</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>ES415</td>\n",
       "      <td>1</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Pharmacology &amp; Pharmacy</td>\n",
       "      <td>1-ES415-Pharmacology &amp; Pharmacy</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ES111</td>\n",
       "      <td>1</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Pharmacology &amp; Pharmacy</td>\n",
       "      <td>1-ES111-Pharmacology &amp; Pharmacy</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>UKJ36</td>\n",
       "      <td>1</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Pharmacology &amp; Pharmacy</td>\n",
       "      <td>1-UKJ36-Pharmacology &amp; Pharmacy</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>NL230</td>\n",
       "      <td>1</td>\n",
       "      <td>External</td>\n",
       "      <td>Immunology</td>\n",
       "      <td>1-NL230-Immunology</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>NL230</td>\n",
       "      <td>1</td>\n",
       "      <td>External</td>\n",
       "      <td>Research &amp; Experimental Medicine</td>\n",
       "      <td>1-NL230-Research &amp; Experimental Medicine</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23668902</th>\n",
       "      <td>23668903</td>\n",
       "      <td>46608429.0</td>\n",
       "      <td>PT11A</td>\n",
       "      <td>6</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Microbiology</td>\n",
       "      <td>6-PT11A-Microbiology</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23668903</th>\n",
       "      <td>23668904</td>\n",
       "      <td>46608438.0</td>\n",
       "      <td>NL337</td>\n",
       "      <td>6</td>\n",
       "      <td>External</td>\n",
       "      <td>Rheumatology</td>\n",
       "      <td>6-NL337-Rheumatology</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23668904</th>\n",
       "      <td>23668905</td>\n",
       "      <td>46608438.0</td>\n",
       "      <td>FR101</td>\n",
       "      <td>6</td>\n",
       "      <td>External</td>\n",
       "      <td>Rheumatology</td>\n",
       "      <td>6-FR101-Rheumatology</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23668905</th>\n",
       "      <td>23668906</td>\n",
       "      <td>46608438.0</td>\n",
       "      <td>PT170</td>\n",
       "      <td>6</td>\n",
       "      <td>External</td>\n",
       "      <td>Rheumatology</td>\n",
       "      <td>6-PT170-Rheumatology</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23668906</th>\n",
       "      <td>23668907</td>\n",
       "      <td>46608438.0</td>\n",
       "      <td>NL326</td>\n",
       "      <td>6</td>\n",
       "      <td>External</td>\n",
       "      <td>Rheumatology</td>\n",
       "      <td>6-NL326-Rheumatology</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23668907 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0       pubid EU_NUTS_ID  period      type  \\\n",
       "0                  1      2010.0      ES415       1  Internal   \n",
       "1                  2      2013.0      ES111       1  Internal   \n",
       "2                  3      2015.0      UKJ36       1  Internal   \n",
       "3                  4      3080.0      NL230       1  External   \n",
       "4                  5      3080.0      NL230       1  External   \n",
       "...              ...         ...        ...     ...       ...   \n",
       "23668902    23668903  46608429.0      PT11A       6  Internal   \n",
       "23668903    23668904  46608438.0      NL337       6  External   \n",
       "23668904    23668905  46608438.0      FR101       6  External   \n",
       "23668905    23668906  46608438.0      PT170       6  External   \n",
       "23668906    23668907  46608438.0      NL326       6  External   \n",
       "\n",
       "                                   subject  \\\n",
       "0                  Pharmacology & Pharmacy   \n",
       "1                  Pharmacology & Pharmacy   \n",
       "2                  Pharmacology & Pharmacy   \n",
       "3                               Immunology   \n",
       "4         Research & Experimental Medicine   \n",
       "...                                    ...   \n",
       "23668902                      Microbiology   \n",
       "23668903                      Rheumatology   \n",
       "23668904                      Rheumatology   \n",
       "23668905                      Rheumatology   \n",
       "23668906                      Rheumatology   \n",
       "\n",
       "                                                ID  count  \n",
       "0                  1-ES415-Pharmacology & Pharmacy     55  \n",
       "1                  1-ES111-Pharmacology & Pharmacy     80  \n",
       "2                  1-UKJ36-Pharmacology & Pharmacy     22  \n",
       "3                               1-NL230-Immunology     32  \n",
       "4         1-NL230-Research & Experimental Medicine     13  \n",
       "...                                            ...    ...  \n",
       "23668902                      6-PT11A-Microbiology     81  \n",
       "23668903                      6-NL337-Rheumatology     52  \n",
       "23668904                      6-FR101-Rheumatology     82  \n",
       "23668905                      6-PT170-Rheumatology     21  \n",
       "23668906                      6-NL326-Rheumatology     65  \n",
       "\n",
       "[23668907 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "affinst = pd.read_csv(dir+'affinst_ed.csv')\n",
    "affinst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f372f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pubid</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>The histamine H-2 receptor antagonistic activi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>We have investigated the ability of several co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>For several years we have been working on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>The structural and ionic requirements for pote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>The effect of taxol on selected lysosomal enzy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032662</th>\n",
       "      <td>10032663</td>\n",
       "      <td>46608401.0</td>\n",
       "      <td>A hallmark of chronic bacterial infections is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032663</th>\n",
       "      <td>10032664</td>\n",
       "      <td>46608410.0</td>\n",
       "      <td>Purpose We sought to describe a disorder clini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032664</th>\n",
       "      <td>10032665</td>\n",
       "      <td>46608423.0</td>\n",
       "      <td>Background For patients with early American Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032665</th>\n",
       "      <td>10032666</td>\n",
       "      <td>46608429.0</td>\n",
       "      <td>Aim of this study The major aim of this work w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032666</th>\n",
       "      <td>10032667</td>\n",
       "      <td>46608438.0</td>\n",
       "      <td>Objective To test the impact of inflammation o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10032667 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0       pubid  \\\n",
       "0                  1      2010.0   \n",
       "1                  2      2012.0   \n",
       "2                  3      2013.0   \n",
       "3                  4      2015.0   \n",
       "4                  5      2019.0   \n",
       "...              ...         ...   \n",
       "10032662    10032663  46608401.0   \n",
       "10032663    10032664  46608410.0   \n",
       "10032664    10032665  46608423.0   \n",
       "10032665    10032666  46608429.0   \n",
       "10032666    10032667  46608438.0   \n",
       "\n",
       "                                                   abstract  \n",
       "0         The histamine H-2 receptor antagonistic activi...  \n",
       "1         We have investigated the ability of several co...  \n",
       "2         For several years we have been working on the ...  \n",
       "3         The structural and ionic requirements for pote...  \n",
       "4         The effect of taxol on selected lysosomal enzy...  \n",
       "...                                                     ...  \n",
       "10032662  A hallmark of chronic bacterial infections is ...  \n",
       "10032663  Purpose We sought to describe a disorder clini...  \n",
       "10032664  Background For patients with early American Jo...  \n",
       "10032665  Aim of this study The major aim of this work w...  \n",
       "10032666  Objective To test the impact of inflammation o...  \n",
       "\n",
       "[10032667 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication = pd.read_csv(dir+'publication_ed.csv')\n",
    "publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf085d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model on: cuda:0\n",
      "\n",
      "=== INTERNAL | ID: 1-ES415-Pharmacology & Pharmacy ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:   0%|          | 0/4 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Embedding: 100%|██████████| 4/4 [02:21<00:00, 35.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INTERNAL | ID: 1-NL327-Pharmacology & Pharmacy ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:   0%|          | 0/1 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Embedding: 100%|██████████| 1/1 [00:11<00:00, 11.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      " - D:/DataforPractice/ContentNovelty/2_knowledge_spaces.csv (61 rows)\n",
      " - D:/DataforPractice/ContentNovelty/2_centroids.csv (2 rows)\n",
      "\n",
      "=== EXTERNAL | ID: 1-ES415-Pharmacology & Pharmacy ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:   0%|          | 0/3 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Embedding: 100%|██████████| 3/3 [02:02<00:00, 40.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXTERNAL | ID: 1-NL327-Pharmacology & Pharmacy ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:   0%|          | 0/3 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Embedding: 100%|██████████| 3/3 [01:46<00:00, 35.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      " - D:/DataforPractice/ContentNovelty/3_external_with_novelty.csv (70 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "### path settings\n",
    "SAVE_PATH = r\"D:/LLM/specter\"                          \n",
    "DATA_DIR = r\"D:/DataforPractice/ContentNovelty/\"       \n",
    "OUT_KNOW = os.path.join(DATA_DIR, \"2_knowledge_spaces.csv\")\n",
    "OUT_CENT = os.path.join(DATA_DIR, \"2_centroids.csv\")\n",
    "OUT_EXT  = os.path.join(DATA_DIR, \"3_external_with_novelty.csv\")\n",
    "\n",
    "### Load LLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(SAVE_PATH)\n",
    "model = AutoModel.from_pretrained(SAVE_PATH)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Device:\", device)\n",
    "print(\"Model on:\", next(model.parameters()).device)\n",
    "\n",
    "# ========= Utils =========\n",
    "def encode_texts(texts, batch_size=16, max_length=512):\n",
    "    \"\"\"SPECTER CLS 임베딩을 배치로 반환 (np.ndarray, shape=[N, D]).\"\"\"\n",
    "    all_vecs = []\n",
    "    for s in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n",
    "        batch = texts[s:s+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch, return_tensors=\"pt\", truncation=True,\n",
    "            padding=True, max_length=max_length\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls = outputs.last_hidden_state[:, 0, :]        # [CLS]\n",
    "        all_vecs.append(cls.detach().cpu().numpy())\n",
    "    return np.vstack(all_vecs) if all_vecs else np.empty((0, model.config.hidden_size))\n",
    "\n",
    "def vec_to_str(v: np.ndarray) -> str:\n",
    "    \"\"\"CSV 저장용: 공백으로 join (읽을 때는 str.split 후 float 변환).\"\"\"\n",
    "    return \" \".join(f\"{x:.6f}\" for x in v.tolist())\n",
    "\n",
    "def str_to_vec(s: str) -> np.ndarray:\n",
    "    return np.array([float(x) for x in s.split(\" \")])\n",
    "\n",
    "# ========= Data =========\n",
    "affinst = pd.read_csv(os.path.join(DATA_DIR, \"affinst_ed.csv\"))\n",
    "publication = pd.read_csv(os.path.join(DATA_DIR, \"publication_ed.csv\"))\n",
    "\n",
    "ID_list = affinst['ID'].unique().tolist()\n",
    "\n",
    "# ========= Pass 1: INTERNAL 임베딩 & 센트로이드 =========\n",
    "rows_know = []   # 세부 관측치(knowledge spaces)\n",
    "rows_cent = []   # (EU_NUTS_ID, period, subject)별 센트로이드\n",
    "\n",
    "for the_id in ID_list:\n",
    "    print(\"\\n=== INTERNAL | ID:\", the_id, \"===\")\n",
    "    df_int = (\n",
    "        affinst.loc[affinst[\"ID\"] == the_id]\n",
    "        .query('type == \"Internal\"')\n",
    "        .merge(publication, on=\"pubid\", how=\"inner\")\n",
    "        .copy()\n",
    "    )\n",
    "    # 제목/초록 정리\n",
    "    df_int = df_int[df_int[\"abstract\"].notna() & (df_int[\"abstract\"].str.strip() != \"\")]\n",
    "    if df_int.empty:\n",
    "        print(\"  -> No Internal rows after filtering. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # df_int[\"input_text\"] = df_int[\"title\"].fillna(\"\") + \" \" + df_int[\"abstract\"].fillna(\"\")\n",
    "    df_int[\"input_text\"] = df_int[\"abstract\"].fillna(\"\")\n",
    "    # 임베딩\n",
    "    vecs = encode_texts(df_int[\"input_text\"].tolist(), batch_size=16)\n",
    "    df_int[\"__emb_vec\"] = list(vecs)\n",
    "\n",
    "    # summary of knowledge_spaces\n",
    "    for _, r in df_int.iterrows():\n",
    "        rows_know.append({\n",
    "            \"ID\": the_id,\n",
    "            \"EU_NUTS_ID\": r[\"EU_NUTS_ID\"],\n",
    "            \"period\": r[\"period\"],\n",
    "            \"subject\": r[\"subject\"],\n",
    "            \"pubid\": r[\"pubid\"],\n",
    "            \"embedding\": vec_to_str(r[\"__emb_vec\"]),   # 직렬화\n",
    "        })\n",
    "\n",
    "    # period-region-subject level centroid\n",
    "    grp = df_int.groupby([\"EU_NUTS_ID\", \"period\", \"subject\"], dropna=False)[\"__emb_vec\"].apply(list)\n",
    "    for (nuts, per, subj), vec_list in grp.items():\n",
    "        mat = np.vstack(vec_list) if len(vec_list) else np.empty((0, model.config.hidden_size))\n",
    "        # Remove NaN\n",
    "        if mat.size == 0:\n",
    "            continue\n",
    "        mat = mat[~np.isnan(mat).any(axis=1)]\n",
    "        if mat.shape[0] == 0:\n",
    "            continue\n",
    "        centroid = mat.mean(axis=0)\n",
    "        rows_cent.append({\n",
    "            \"ID\": the_id,\n",
    "            \"EU_NUTS_ID\": nuts,\n",
    "            \"period\": per,\n",
    "            \"subject\": subj,\n",
    "            \"centroid\": vec_to_str(centroid),\n",
    "            \"n_docs\": mat.shape[0],\n",
    "        })\n",
    "\n",
    "df_know = pd.DataFrame(rows_know)\n",
    "df_cent = pd.DataFrame(rows_cent)\n",
    "if not df_know.empty:\n",
    "    df_know.to_csv(OUT_KNOW, index=False)\n",
    "if not df_cent.empty:\n",
    "    df_cent.to_csv(OUT_CENT, index=False)\n",
    "print(f\"\\nSaved:\\n - {OUT_KNOW} ({len(df_know)} rows)\\n - {OUT_CENT} ({len(df_cent)} rows)\")\n",
    "\n",
    "# ========= Pass 2: EXTERNAL 임베딩 & novelty(centroid와의 코사인 거리) =========\n",
    "# centroid 딕셔너리: (EU_NUTS_ID, period, subject) → np.ndarray\n",
    "centroids = {\n",
    "    (row[\"EU_NUTS_ID\"], row[\"period\"], row[\"subject\"]): str_to_vec(row[\"centroid\"])\n",
    "    for _, row in df_cent.iterrows()\n",
    "}\n",
    "\n",
    "rows_ext = []\n",
    "for the_id in ID_list:\n",
    "    print(\"\\n=== EXTERNAL | ID:\", the_id, \"===\")\n",
    "    df_ext = (\n",
    "        affinst.loc[affinst[\"ID\"] == the_id]\n",
    "        .query('type == \"External\"')\n",
    "        .merge(publication, on=\"pubid\", how=\"inner\")\n",
    "        .copy()\n",
    "    )\n",
    "    df_ext = df_ext[df_ext[\"abstract\"].notna() & (df_ext[\"abstract\"].str.strip() != \"\")]\n",
    "    if df_ext.empty:\n",
    "        print(\"  -> No External rows after filtering. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # df_ext[\"input_text\"] = df_ext[\"title\"].fillna(\"\") + \" \" + df_ext[\"abstract\"].fillna(\"\")\n",
    "    df_ext[\"input_text\"] = df_ext[\"abstract\"].fillna(\"\")\n",
    "    vecs_ext = encode_texts(df_ext[\"input_text\"].tolist(), batch_size=16)\n",
    "    df_ext[\"__emb_vec\"] = list(vecs_ext)\n",
    "\n",
    "    def compute_novelty(row):\n",
    "        key = (row['EU_NUTS_ID'], row['period'], row['subject'])\n",
    "        centroid = centroids.get(key)\n",
    "        if centroid is None:\n",
    "            return np.nan\n",
    "        v = row[\"__emb_vec\"]\n",
    "        if np.isnan(v).any():\n",
    "            return np.nan\n",
    "        return float(cosine_distances(v.reshape(1, -1), centroid.reshape(1, -1))[0][0])\n",
    "\n",
    "    df_ext[\"content_novelty\"] = df_ext.apply(compute_novelty, axis=1)\n",
    "\n",
    "    rows_ext.extend(df_ext[[\n",
    "        \"ID\",\"EU_NUTS_ID\",\"period\",\"subject\",\"pubid\",\"content_novelty\"\n",
    "    ]].to_dict(\"records\"))\n",
    "\n",
    "df_ext_out = pd.DataFrame(rows_ext)\n",
    "if not df_ext_out.empty:\n",
    "    df_ext_out.to_csv(OUT_EXT, index=False)\n",
    "    print(f\"\\nSaved:\\n - {OUT_EXT} ({len(df_ext_out)} rows)\")\n",
    "else:\n",
    "    print(\"\\nNo External novelty rows to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe1e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5a877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eced054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\ProgramData\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\torch\\cuda\\__init__.py:287: UserWarning: \n",
      "NVIDIA GeForce RTX 5090 with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'builtin_function_or_method' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# [CLS] token\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 32\u001b[0m affinst \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maffinst_ed.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m)\n\u001b[0;32m     33\u001b[0m publication \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_ed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m ID_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1-ES415-Pharmacology & Pharmacy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1-NL327-Pharmacology & Pharmacy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'builtin_function_or_method' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "### Load model\n",
    "# SAVE_PATH = r\"D:/LLM/Llama4-Scout\"             \n",
    "SAVE_PATH = r\"D:/LLM/specter\"             \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(SAVE_PATH)\n",
    "model = AutoModel.from_pretrained(SAVE_PATH) #, torch_dtype=torch.float16, device_map=\"auto\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)  \n",
    "print(next(model.parameters()).device)  \n",
    "\n",
    "# Function to get SPECTER embedding\n",
    "def get_specter_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "    return embedding.squeeze().cpu().numpy()\n",
    "\n",
    "affinst = pd.read_csv(dir+'affinst_ed.csv')\n",
    "publication = pd.read_csv(dir+'publication_ed.csv')\n",
    "\n",
    "ID_list = ['1-ES415-Pharmacology & Pharmacy','1-NL327-Pharmacology & Pharmacy']\n",
    "\n",
    "for i in ID_list:\n",
    "    \n",
    "    print(i)  \n",
    "\n",
    "    df = affinst[affinst['ID'] == i].copy()\n",
    "    df = df[df.type==\"Internal\"]\n",
    "    df = pd.merge(df, publication, on='pubid', how='inner')\n",
    "    df = df[df['abstract'].notna()]\n",
    "\n",
    "    embeddings_test = []\n",
    "    for text in tqdm(df['abstract'], desc=\"Embedding test group\"):\n",
    "        emb = get_specter_embedding(text)\n",
    "        embeddings_test.append(emb)\n",
    "\n",
    "    # Store embeddings\n",
    "    df['embedding'] = embeddings_test\n",
    "\n",
    "    # Compute centroid\n",
    "    test_vectors = np.stack(df['embedding'].to_numpy())\n",
    "    test_centroid = np.mean(test_vectors, axis=0)\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    import numpy as np\n",
    "\n",
    "    knowledge_spaces = defaultdict(list)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        key = (row['EU_NUTS_ID'], row['period'], row['subject'])\n",
    "        knowledge_spaces[key].append(row['embedding'])\n",
    "\n",
    "    # Compute centroids for each group\n",
    "    centroids = {k: np.mean(vectors, axis=0) for k, vectors in knowledge_spaces.items()}\n",
    "\n",
    "    knowledge_spaces.to_csv('2_knowledge_spaces.csv', index=False)\n",
    "    centroids.to_csv('2_centroids.csv', index=False)\n",
    "\n",
    "# Output\n",
    "print(\"\\n✅ Embedding and centroid calculation complete.\")\n",
    "print(\"Number of documents in group:\", len(df))\n",
    "print(\"Centroid shape:\", test_centroid.shape) # 768-dimensional vector\n",
    "print(\"Sample of centroid values:\", test_centroid[:10]) # the first 10 values of the 768-dimensional centroid vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb3e762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     The histamine H-2 receptor antagonistic activi...\n",
       "1     Cyclosporin A (CsA) is a potent immunosuppress...\n",
       "2     Neurotrophins are molecules that regulate the ...\n",
       "3     Starting with 12-acetoxy-7,9(11)-drimadiene, p...\n",
       "4                                                   NaN\n",
       "                            ...                        \n",
       "90    1 An oxazolo(3,2-a)pyridine derivative P5, des...\n",
       "91    A new GC-MS method for monitoring lignans was ...\n",
       "92    Two new diterpcnic acids with an ent-halimane ...\n",
       "93    Taking the natural cardenolides as a model for...\n",
       "94    The cyclolignan family of natural products inc...\n",
       "Name: abstract, Length: 95, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['abstract']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
